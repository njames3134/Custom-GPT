# Custom-GPT
Implementation of a Generative Pre-trained Transformer (GPT) based on Google's *Attention is all you need* paper: https://arxiv.org/pdf/1706.03762  
Trained on a Wikipedia dump dataset from the August 8th, 2020 Wikipedia archive dump: https://www.kaggle.com/datasets/toastedalmonds/wikipedia-dump-20200820?resource=download (17 GB)
